{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee03d2d-906b-4dee-aee1-b48f2a17a887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "693713e8-32a9-4cdc-b26d-2452ac17bd32",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a440c-feb4-4003-99ca-5fece3c4c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRegressor:\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "class LinearRegressor:\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "class RidgeRegressor:\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "# optional: Lasso and ElasticNet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class ElasticNetRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a11bb3-27bc-4150-81ba-ce76bd730521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe53c2c-e0b2-414e-8f8e-1e7de822988d",
   "metadata": {},
   "source": [
    "# Iterative methods\n",
    "\n",
    "We can see above that a linear regression problem can be solved directly\n",
    "\n",
    "What happens when we can't invert the matrix?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded777f9-20ec-4417-a6dd-154fd9807657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LinearRegressionIterative(BaseRegressor):\n",
    "    \n",
    "    \n",
    "    def zero_grad(self):\n",
    "        pass\n",
    "    \n",
    "    def backward(self, true_values, output_values):\n",
    "        \"\"\"\n",
    "        Numerically calculate the gradient of the loss function wrt the current weights\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def step(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "# optimizer.zero_grad()   # zero the gradient buffers\n",
    "# output = net(input)\n",
    "# loss = criterion(output, target)\n",
    "# loss.backward()\n",
    "# optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72c9b2-62f7-4d22-b5e4-ab321d31d65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797e3026-00e0-47ca-bfad-ddf03314bebb",
   "metadata": {},
   "source": [
    "# Improving convergence with alternative optimizers and second-order methods\n",
    "\n",
    "+ Need a dataset where Linear regression fails\n",
    "+ Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169637b0-6a6e-4e14-852a-d6115f698300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
